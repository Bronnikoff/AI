{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "19KTco8R8eHc"
   },
   "source": [
    "#### Бронников Максим Андреевич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDnvrSmp8eHh"
   },
   "source": [
    "*М8О-307Б-17, №4 по списку*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_pVM1NJ8eHk"
   },
   "source": [
    "max120199@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KiAC6M_08eHm"
   },
   "source": [
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Bronnikoff/GenerationP/blob/master/GenerationP.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/MAILabs-Edu-AI/lab-sequence-generation-Bronnikoff/blob/master/GenerationP.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2pRqtso8eHv"
   },
   "source": [
    "<h1>  <center>Лабораторная работа №3</center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gh1K84Be8eHx"
   },
   "source": [
    "<h2> <center> Генерация текста </center> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kROd33NL8eH0"
   },
   "source": [
    "### Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wg7GaG8n8eH3"
   },
   "source": [
    "В данной лабораторной работе вам предстоит научиться генерировать последовательности типа, заданного по варианту, с помощью рекуррентных нейронных сетей.\n",
    "Необходимо исследовать несколько различных нейросетевых архитектур:\n",
    "\n",
    "* Обычная полносвязная RNN\n",
    "* Однослойная LSTM\n",
    "* Двухслойная LSTM\n",
    "* Однослойный GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fd1FB6oH8eH5"
   },
   "source": [
    "**Вариант №4:** Проза на английском языке, элемент последовательности - одно слово."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "SYorIsIL8eH8",
    "outputId": "c352a976-1d11-4368-d26f-93d0c3ca2896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 7.0MB 2.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 9.7MB 46.6MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 501kB 58.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 3.7MB/s \n",
      "\u001b[?25h  Building wheel for tornado (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: google-colab 1.0.0 has requirement notebook~=5.2.0, but you'll have notebook 6.0.3 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install jupyterthemes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SDo7qSV8eIh"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, LSTM, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Dense, SimpleRNN\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('all')\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from jupyterthemes import jtplot\n",
    "matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "jtplot.style('onedork')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TEkCBzuf8eIv"
   },
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dFQ608P8eIx"
   },
   "source": [
    "#### Источник данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jaBuswLL8eI0"
   },
   "source": [
    "Для составления датасета я воспользовался сайтом http://www.gutenberg.org с книгами, доступными для свободного скачивания.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSl4exOs8eI7"
   },
   "source": [
    "Списки книг вместе с ссылками на них:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7wyMc-Uk8eI9"
   },
   "outputs": [],
   "source": [
    "books = [\"dorian_grey.txt\", \n",
    "         \"principe.txt\", \n",
    "         \"crime.txt\",\n",
    "         \"karenina.txt\",\n",
    "         \"baskerwill.txt\",\n",
    "         \"woman.txt\",\n",
    "         \"twist.txt\",\n",
    "         \"good.txt\",\n",
    "         \"garden.txt\"]\n",
    "\n",
    "urls = [\"http://www.gutenberg.org/cache/epub/174/pg174.txt\", \n",
    "        \"http://www.gutenberg.org/cache/epub/1232/pg1232.txt\",\n",
    "        \"https://www.gutenberg.org/files/2554/2554-0.txt\",\n",
    "        \"https://www.gutenberg.org/files/1399/1399-0.txt\",\n",
    "        \"https://www.gutenberg.org/files/2852/2852-0.txt\",\n",
    "        \"http://www.gutenberg.org/cache/epub/514/pg514.txt\",\n",
    "        \"http://www.gutenberg.org/cache/epub/730/pg730.txt\", \n",
    "        \"http://www.gutenberg.org/cache/epub/4363/pg4363.txt\",\n",
    "        \"https://www.gutenberg.org/files/113/113-0.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J27QRTjo8eJW"
   },
   "source": [
    "#### Скачивание и обработка данных:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p-1rTtix8eJZ"
   },
   "source": [
    "Мы будем скачивать книги из списка, обрабатывать их, логически разбивать и объеденять их в один большой сет слов. Для этого опишем необходимые функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MA4sVHcu8eJb"
   },
   "source": [
    "За скачивание текста отвечает встроенная в *keras* функция **get_file**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UA-YuAq8eJf"
   },
   "source": [
    "Импорт текста из скачанной книги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPF1e-Yc8eJi"
   },
   "outputs": [],
   "source": [
    "def text_from_file(filepath):\n",
    "    text = \"\"\n",
    "    with open(filepath, 'rb') as book:\n",
    "        text = book.read().decode(encoding='utf-8')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhhB6uLQ8eJ_"
   },
   "source": [
    "Импортированный текст помимо самого произведения несет информацию о самой книге, котороая засоряет текст. Попробуем очистить данные. Для очистки и обработки данных будем использовать *nltk*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LUDqu0t58eKC"
   },
   "source": [
    "Все книги *Проекта Гутенберг* имеют ряд технической информации в начале и конце. При этом для разделения этой информации от самого текста книги в каждом файле есть 2 сигнальные строки в начале и конце. Достанем текст, коорые между ними:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ET17FzEL8eKE"
   },
   "outputs": [],
   "source": [
    "# May be done by regex more effective, but it works\n",
    "def clear_gutenberg(text):\n",
    "    # The first lines before \"*** START PROJECT .... ***\" useless\n",
    "    # cut text before this line\n",
    "    text = text[text.find(\"*** START\"):]\n",
    "    # and cut this line too\n",
    "    text = text[text.find(\"\\n\"):]\n",
    "    # and lines after \"*** END OF\" also useless, cut this\n",
    "    return text[:text.find(\"*** END OF\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEgsF6bg8eKT"
   },
   "source": [
    "Некоторые книгии содержат места для вставок иллюстраций. Удалим эти вставки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXNhQ3ny8eKV"
   },
   "outputs": [],
   "source": [
    "def clear_inserts(text):\n",
    "    return \"\".join(text.split(\"[Illustration]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VP35OHVq8eKo"
   },
   "source": [
    "Но приведенная выше очистка недостаточна, поэтому разделим текст по главам, чтобы потом из них состовлять логически связанные последовательности. Возможны случаи, когда слово \"chapter\"\n",
    "встретится в тексте книги, однако считаем что такое разделение будет не фатальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqQZCOSF8eKq"
   },
   "outputs": [],
   "source": [
    "def split_by_chapter(text, minlen = 1000):\n",
    "    ans = []\n",
    "    # search  chapter line:\n",
    "    search_res = re.search('\\n\\s*chapter[^\\n]+\\n', text, flags=re.IGNORECASE)\n",
    "    # if book without chapter this func return []\n",
    "    if search_res is None:\n",
    "        return ans\n",
    "    # index of first chapter\n",
    "    i = search_res.span()[1]\n",
    "    # and cat all text before with line:\n",
    "    text = text[i+1:]\n",
    "    \n",
    "    #do while:\n",
    "    search_res = re.search('\\n\\s*chapter[^\\n]+\\n', text, flags=re.IGNORECASE)\n",
    "    while not search_res is None:\n",
    "        # searchnew chapter line\n",
    "        match = search_res.span()\n",
    "        # take all text before\n",
    "        to_add = text[:match[0]]\n",
    "        # but it may be content-list, check by len of chapter:\n",
    "        if len(to_add) > minlen:\n",
    "            ans.append(text[:match[0]])\n",
    "        # and cut this text with chapter line\n",
    "        text = text[match[1]:]\n",
    "        # search new chapter line\n",
    "        search_res = re.search('\\n\\s*chapter[^\\n]+\\n', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # add last chapter\n",
    "    ans.append(text)\n",
    "    # retun splited text\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EsZIn6cZ8eLD"
   },
   "source": [
    "Тогда объединенный текст глав всех книг можно получить объеденив вышеописанные функции. Объединённый текст - список из глав-текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2lThXfS8eLI"
   },
   "outputs": [],
   "source": [
    "def chapters_from_books(books, urls):\n",
    "    chapters = []\n",
    "    for book, url in zip(books, urls):\n",
    "        #download book:\n",
    "        filepath = tf.keras.utils.get_file(book, url)\n",
    "        # clear gutenberg info\n",
    "        text = clear_gutenberg(text_from_file(filepath))\n",
    "        # split by chapters, clear inserts and extend big dataset\n",
    "        chapters.extend(split_by_chapter(clear_inserts(text)))\n",
    "    return chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxuyFnW58eLT"
   },
   "source": [
    "Теперь можно перевести текст  в список слов проведя токенизацию текста. Некоторые, стоящие в одинаковой форме, но в разном регистре могут существенно повлиять на размер словаря и на качество модели, поэтому проведем небольшую предобработку: переведем все несобственные слова в нижний регистр. Для этого воспользуемся **pos_tag** из  *nltk* для поиска имен собственных.\n",
    "\n",
    "Обычно для задач машинного обучения используют очистку от стоп-слов и преобразование к нормальной форме для наилучшего поиска смысловых связей между словами, однако наша задача как можно более похоже сымитировать человеческий текст, структура которого наполнена различными знаками препинания, междометиями и предлогами. Поэтому оставляем их в тексте в качестве отдельных слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2cNhEcVq8eLV"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    #list of words\n",
    "    ans = []\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "    for tag in tagged:\n",
    "        if tag[1] != 'NNP':\n",
    "            ans.append(tag[0].lower())\n",
    "        else:\n",
    "            ans.append(tag[0])\n",
    "    # list of lower words\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEztNOI18eLl"
   },
   "source": [
    "Тогда функция получения списка токенезированных глав:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9WAx5kj8eLr"
   },
   "outputs": [],
   "source": [
    " def tokenize_data(chapters):\n",
    "        ans = []\n",
    "        for chapter in tqdm(chapters):\n",
    "            ans.append(tokenize_text(chapter))\n",
    "        return ans\n",
    "#         return = list(map(tokenize_text, chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbrtcHOX8eL1"
   },
   "source": [
    "Импортируем данные с применением полученных функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "8vXD0ZoK8eL4",
    "outputId": "2d793d03-c5c0-4133-9556-766dd5b7e5fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.gutenberg.org/cache/epub/174/pg174.txt\n",
      "466944/462075 [==============================] - 2s 5us/step\n",
      "Downloading data from http://www.gutenberg.org/cache/epub/1232/pg1232.txt\n",
      "311296/305853 [==============================] - 2s 5us/step\n",
      "Downloading data from https://www.gutenberg.org/files/2554/2554-0.txt\n",
      "1204224/1201735 [==============================] - 4s 3us/step\n",
      "Downloading data from https://www.gutenberg.org/files/1399/1399-0.txt\n",
      "2072576/2068079 [==============================] - 4s 2us/step\n",
      "Downloading data from https://www.gutenberg.org/files/2852/2852-0.txt\n",
      "393216/388106 [==============================] - 2s 5us/step\n",
      "Downloading data from http://www.gutenberg.org/cache/epub/514/pg514.txt\n",
      "1056768/1053504 [==============================] - 3s 3us/step\n",
      "Downloading data from http://www.gutenberg.org/cache/epub/730/pg730.txt\n",
      "942080/936253 [==============================] - 3s 3us/step\n",
      "Downloading data from http://www.gutenberg.org/cache/epub/4363/pg4363.txt\n",
      "409600/408778 [==============================] - 2s 5us/step\n",
      "Downloading data from https://www.gutenberg.org/files/113/113-0.txt\n",
      "483328/475383 [==============================] - 2s 5us/step\n",
      "\n",
      "Общий текст состоит из 476 глав!\n"
     ]
    }
   ],
   "source": [
    "chaps = chapters_from_books(books, urls)\n",
    "\n",
    "print('\\nОбщий текст состоит из {} глав!'.format(len(chaps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hBzRGxC08eMN"
   },
   "source": [
    "И токенезируем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Rw3_0nju8eMP",
    "outputId": "1f0fadd1-ed30-4f65-e4cb-c8499c9dc6cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:52<00:00,  9.05it/s]\n"
     ]
    }
   ],
   "source": [
    "chaps = tokenize_data(chaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VHWSDMA8eMl"
   },
   "source": [
    "На данный момент мы преобразовали книги в последовательности слов, разбитые по главам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0lNNkiF8eMs"
   },
   "source": [
    "#### Разбитие текста на последовательности слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j__mN98e8eMt"
   },
   "source": [
    "Разбивка будет происходить на последовательности длины **SEQ_LENGTH**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRCAOJTX8eMv"
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHn9smis8eM6"
   },
   "source": [
    "Каждую главу разбиваем на последовательности длины **SEQ_LENGTH + 1**, после чего производим объединение глав в один датасет. Разбитие было нужно для того, чтобы конец одной главы не засорял начало другой. В данном варианте мы избавляемся от последних слов глав."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWNKnYkA8eM_"
   },
   "outputs": [],
   "source": [
    "def chapter_sequences(chapter, seq_len = 51):\n",
    "    sequences = []\n",
    "    i = 0\n",
    "    for j in range(seq_len, len(chapter), seq_len):\n",
    "        sequences.append(chapter[i:j])\n",
    "        i = j\n",
    "    return sequences\n",
    "\n",
    "def sequences_set(chapters, seq_len = 50):\n",
    "    sequences = []\n",
    "    for chapter in tqdm(chapters):\n",
    "        sequences.extend(chapter_sequences(chapter, seq_len))\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "X0i-Qhm_8eNJ",
    "outputId": "93244d9b-de41-4a52-cca8-4c8d376ed107"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:00<00:00, 9577.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общий датасет содержит 22376 последовательности!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seqs = sequences_set(chaps, SEQ_LENGTH + 1)\n",
    "print('Общий датасет содержит {} последовательности!'.format(len(seqs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN-vE1WB8eNX"
   },
   "source": [
    "#### Создание словаря и векторизация слов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9nSq-908eNZ"
   },
   "source": [
    "За создание словаря и векторизацию слов будет ответственнена модель *Word2Vec*, которая позволит находить логические взаимосвязи между словами последовательностей слов. В словарь будут добавляться слова, которые встречались в объединенном сете хотя бы **MIN_COUNT** раз. Это нужно для экономии ресурсов и для более качественного распознавания связей в последовательностях.\n",
    "\n",
    "Далее нужно будет осторожно обращаться с теми словами, которые не попали в словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XLS-1_zx8eNb"
   },
   "source": [
    "*Word2Vec* затратный метод, однако он позволит нам создать предобученную матрицу из векторов для каждого из слов, которую можно использовать в качестве входного слоя нашей *RNN* для повышения качества обученной в последствии модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Tvhlw9WU8eNd",
    "outputId": "c9ca92fd-c774-4f24-905b-b8addc6d2a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель обучалась 79.27673578262329 секунд\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "w2v = Word2Vec(seqs, min_count=2, size = 510, workers = 4, iter = 27, alpha = 0.1)\n",
    "end = time.time()\n",
    "\n",
    "print('\\nМодель обучалась {} секунд'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_8G3qMx8eNs"
   },
   "source": [
    "Для обучения слов необходимо преобразовать их в численный вид, а для интерпретации ответов *RNN*, напротив, нужно преобразовать числа в слова. Для этого создадим 2 структуры с биективным отображением одной в другую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Aiu9_4H8eNu"
   },
   "outputs": [],
   "source": [
    "def enumerated_w2v_vocabs(w2v):\n",
    "    word2idx = {}\n",
    "    idx2word = []\n",
    "    for word in w2v.wv.vocab:\n",
    "        word2idx[word] = len(idx2word)\n",
    "        idx2word.append(word)\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "u319IEEL8eN6",
    "outputId": "e04cc186-8df0-4bce-cb16-bae5fc252ece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Размер словаря: 20353 слов\n"
     ]
    }
   ],
   "source": [
    "word2idx, idx2word = enumerated_w2v_vocabs(w2v)\n",
    "# convert to numpy for comfortable converts\n",
    "idx2word = np.array(idx2word)\n",
    "print('\\nРазмер словаря: {} слов'.format(len(idx2word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IfDfBum18eOX"
   },
   "source": [
    "#### Тренировочный датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk8fdY3J8eOZ"
   },
   "source": [
    "Теперь мы можем преобразовать список последовательностей слов в датасет численных тензоров длины **SEQ_LENGTH**, разбитых на пакеты размера **BATCH_SIZE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mZUPNEE8eOf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moYp3P1r8eOp"
   },
   "source": [
    "Функция перевода слова в число. Для слов, не присутствующих в словаре будем грубо возращать дефолтное значение, которое по умолчанию для симола *точка*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "582vroM48eOr"
   },
   "outputs": [],
   "source": [
    "def word_to_int(word, word2idx, default = '.'):\n",
    "    if word in word2idx:\n",
    "        return word2idx[word]\n",
    "    return word2idx[default]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LbaZ7-oe8eOz"
   },
   "source": [
    "Функция перевода списка последовательностей слов в список последовательностей индексов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lGWxhxW-8eO1"
   },
   "outputs": [],
   "source": [
    "def integer_sequences(sequences, word2idx):\n",
    "    ans = []\n",
    "    converter = lambda x: word_to_int(x, word2idx)\n",
    "    for seq in tqdm(sequences):\n",
    "        ans.append(list(map(converter, seq)))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNY9c65Y8eO-"
   },
   "source": [
    "Переведём последовательности чисел в тензорный вид. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bZl9fNk38ePA",
    "outputId": "8fb1be85-0a21-44fc-f171-e31c1b8d6b86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22376/22376 [00:00<00:00, 52980.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = integer_sequences(seqs, word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mL-sfbXt8ePS"
   },
   "source": [
    "К этому моменту мы имеем набор из последовательностей по **SEQ_LENGTH + 1** чисел. Для обучения следует разбить этот датасет на 2 столбца:\n",
    "\n",
    "1. Обучающие последовательности из перых SEQ_LENGTH элементов.\n",
    "2. Тестовые последовательности из последних SEQ_LENGTH элементов.\n",
    "    \n",
    "Так каждому слову последовательности в обучающей части будет поставлено в соответствие следующее по порядку слово в тестовой части тренировочного набора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnh4wB_v8ePX"
   },
   "outputs": [],
   "source": [
    "# Code from tensorflow tutuorial\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = dataset.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJczx-IL8ePg"
   },
   "source": [
    "Для ускорения обучения и лучшей апроксимации уреднённого градиента от всего набора при обучении перемешаем последовательности в наборе и разобъем их на наборы по **BATCH_SIZE** элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IhVCUzw98ePh",
    "outputId": "baecf7e5-f944-448b-e14d-e0857050a027"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 65), (128, 65)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code from tensorflow tutuorial\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I0H6LGLR8ePr"
   },
   "source": [
    "Датасет готов к обучению модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUjhyGYM8ePt"
   },
   "source": [
    "### Проектирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2JrBhB-8ePv"
   },
   "source": [
    "#### Полносвязная RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_O-cfJli8ePw"
   },
   "source": [
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJcaVxjy8ePy"
   },
   "outputs": [],
   "source": [
    "RNN_DIR = \"./full_rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvFieFmn8eP-"
   },
   "outputs": [],
   "source": [
    "! mkdir -p full_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_d-j6p2L8eQL"
   },
   "source": [
    "Наша *полносвязная RNN* будет состоять из следующих слоёв:\n",
    "1. Входной *embedding* слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной *Word2Vec* модели.\n",
    "\n",
    "2. Полносвязный рекуррентный слой с функцией инициализации *Ксавьера*, требуемый по заданию.\n",
    "\n",
    "\n",
    "3. Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zM2TH1dL8eQM"
   },
   "outputs": [],
   "source": [
    "def ModelRNN(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        SimpleRNN(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 4 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYOtrWTm8eQV"
   },
   "source": [
    "#### Однослойная LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psFeLVFl8eQd"
   },
   "source": [
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hq1C5tEa8eQe"
   },
   "outputs": [],
   "source": [
    "SINGLE_DIR = \"./single_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wcz4-kXt8eQp"
   },
   "outputs": [],
   "source": [
    "! mkdir -p single_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZF8HBc358eQ8"
   },
   "source": [
    "Наша *однослойная LSTM* будет состоять из следующих слоёв:\n",
    "1. Входной *embedding* слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной *Word2Vec* модели.\n",
    "\n",
    "2. *LSTM* слой с функцией инициализации *Ксавьера*, требуемый по заданию.\n",
    "\n",
    "3. Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXrKUF1w8eQ9"
   },
   "outputs": [],
   "source": [
    "def ModelSingleLSTM(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        LSTM(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 4 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3yS3RNf8eRG"
   },
   "source": [
    "#### Двухслойная LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaBRWQRT8eRI"
   },
   "source": [
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zruKkNFc8eRK"
   },
   "outputs": [],
   "source": [
    "DOUBLE_DIR = \"./double_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ddLRzfZ8eRc"
   },
   "outputs": [],
   "source": [
    "! mkdir -p double_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NC2nTyn8eR-"
   },
   "source": [
    "Наша *двухслойная LSTM* будет состоять из следующих слоёв:\n",
    "1. Входной *embedding* слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной *Word2Vec* модели.\n",
    "\n",
    "2. Первый *LSTM* слой с функцией инициализации *Ксавьера*, требуемый по заданию.\n",
    "3. Второй *LSTM* слой с функцией инициализации *Ксавьера*, требуемый по заданию.\n",
    "\n",
    "4. Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TIpn7K9y8eSH"
   },
   "outputs": [],
   "source": [
    "def ModelDoubleLSTM(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        LSTM(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        LSTM(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'),\n",
    "      # 4 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 5 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUvaLJJs8eSR"
   },
   "source": [
    "#### Однослойный GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tow6Fxvm8eST"
   },
   "source": [
    "Директория для данных модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTNRw_Jv8eSV"
   },
   "outputs": [],
   "source": [
    "GRU_DIR = \"./single_gru\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "auMkDsRp8eSj"
   },
   "outputs": [],
   "source": [
    "! mkdir -p single_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i3_-rlkq8eSx"
   },
   "source": [
    "Наша *однослойная GRU* будет состоять из следующих слоёв:\n",
    "1. Входной *embedding* слой, преобразующий все слова последовательностей в векторный вид. Этот слой будет начально иницализирован весами предобученной *Word2Vec* модели.\n",
    "\n",
    "2. *GRU* слой с функцией инициализации *Ксавьера*, требуемый по заданию.\n",
    "\n",
    "3. Выходной слой сети с размерностью - размером словаря."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yyub4Bpv8eSy"
   },
   "outputs": [],
   "source": [
    "def ModelGRU(w2v, batch_size, rnn_units = 512, neuros = 128, drop_rate = 0.1):\n",
    "    vocab_size = len(w2v.wv.vocab)\n",
    "    model = Sequential([\n",
    "      # 1 layer\n",
    "        Embedding(vocab_size, w2v.vector_size, \n",
    "                  batch_input_shape=[batch_size, None], weights=[w2v.wv.vectors]),\n",
    "      # 2 layer \n",
    "        GRU(rnn_units, return_sequences=True, stateful=False, \n",
    "          recurrent_initializer='glorot_uniform'), \n",
    "      # 3 layer\n",
    "        #Dropout(drop_rate),\n",
    "        #BatchNormalization(),\n",
    "        #Dense(neuros, kernel_initializer=\"he_uniform\", activation='relu'),\n",
    "      # 4 layer\n",
    "        Dense(vocab_size, kernel_initializer=\"glorot_uniform\")\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XM6v3kMG8eTD"
   },
   "source": [
    "#### Гиперпараметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z8O49JcW8eTF"
   },
   "source": [
    "*rnn_units*, *neuros* и *drop_rate* - гиперпараметры модели, которые следует настраивать для получения наилучшего результата. Также гиперпараметрами являются и длина последовательностей вместе с размером пакетов, однако их настройка происходит раньше, поскольку от них зависит формат данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOihKoMq8eTN"
   },
   "source": [
    "### Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RIjGO7E8eTO"
   },
   "source": [
    "При обучении полезно сохранять параметры обученной модели в *чекпоинты*. Для этого при обучении модели следует передать ей структуру, созданием которой занимается эта функция."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7jYEU8Q8eTQ"
   },
   "outputs": [],
   "source": [
    "def checkpoint_creator(checkpoint_dir = \"./\"):\n",
    "    checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoints/ckpt_model\")\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"loss\", \n",
    "                                          filepath=checkpoint_prefix,\n",
    "                                          save_weights_only=True, \n",
    "                                          save_best_only=True)\n",
    "    return checkpoint_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5VN_Ql58eTZ"
   },
   "source": [
    "Функция потерь, используемая при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "82a35lEx8eTe"
   },
   "outputs": [],
   "source": [
    "# code from tensorflow tutorial\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SRZ0b1cN8eTn"
   },
   "source": [
    "Общие гиперпараметры моделей опишем здесь. В большинстве случаев для отдельной модели необходимо подбирать отдельные гиперпараметры, однако в данном случае нас интересует сравнить работу разных архетектур нейросетевых моделей, для чего лучше работать с фиксированным набором параметров для всех моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VeQ1n-m48eTz"
   },
   "outputs": [],
   "source": [
    "RATE = 0.15\n",
    "NEUROS = 512\n",
    "UNITS = 1024\n",
    "\n",
    "EPOCHS = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2gKa7Juy0S9u"
   },
   "source": [
    "Соберём модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L9qm39Pq8eT-"
   },
   "source": [
    "*Полносвязная RNN:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "FGkXv2WI8eUB",
    "outputId": "4616bc96-f28c-4c0b-eb2c-5b027b825872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 510)          10380030  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (128, None, 1024)         1571840   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 20353)        20861825  \n",
      "=================================================================\n",
      "Total params: 32,813,695\n",
      "Trainable params: 32,813,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simple_rnn = ModelRNN(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "simple_rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SPObHoKR8eU1"
   },
   "source": [
    "*Однослойная LSTM:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "qQnSb4yW8eU3",
    "outputId": "d227acd5-79c2-42b0-8881-16c275ca5d20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (128, None, 510)          10380030  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (128, None, 1024)         6287360   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (128, None, 20353)        20861825  \n",
      "=================================================================\n",
      "Total params: 37,529,215\n",
      "Trainable params: 37,529,215\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_lstm = ModelSingleLSTM(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "single_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dz0KtbnR8eVH"
   },
   "source": [
    "*Двухслойная LSTM:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "_aSz5mMx8eVI",
    "outputId": "3c9d6eb8-7a88-40a2-9678-fc88abaea737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (128, None, 510)          10380030  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (128, None, 1024)         6287360   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (128, None, 1024)         8392704   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, None, 20353)        20861825  \n",
      "=================================================================\n",
      "Total params: 45,921,919\n",
      "Trainable params: 45,921,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "double_lstm = ModelDoubleLSTM(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "double_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MUxEGVnR8eVs"
   },
   "source": [
    "*Однослойная GRU:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "jNt7NKcT8eVt",
    "outputId": "f40bb2ff-cfde-448e-c0f4-c0bab0c70993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (128, None, 510)          10380030  \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1024)         4718592   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (128, None, 20353)        20861825  \n",
      "=================================================================\n",
      "Total params: 35,960,447\n",
      "Trainable params: 35,960,447\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "single_gru = ModelGRU(w2v, BATCH_SIZE, UNITS, NEUROS, RATE)\n",
    "\n",
    "single_gru.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZAWhHaMq8eWK"
   },
   "source": [
    "Скомпилируем, используя стандартный оптимизатор Адама. В качестве функции потерь используем описанную выше кроссэнтропию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IFUlr4Qi8eWT"
   },
   "outputs": [],
   "source": [
    "simple_rnn.compile(optimizer='adam', loss=loss)\n",
    "single_lstm.compile(optimizer='adam', loss=loss)\n",
    "double_lstm.compile(optimizer='adam', loss=loss)\n",
    "single_gru.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4qAlzhB8eWj"
   },
   "source": [
    "Обучим модели, используя раннюю остановку при достижении хорошего результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "R3i-FZje8eWk",
    "outputId": "530e57a2-ef1d-4614-8578-453520c5c135",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение полносвязной RNN модели:\n",
      "Epoch 1/90\n",
      "174/174 [==============================] - 51s 292ms/step - loss: 6.0801\n",
      "Epoch 2/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 5.1007\n",
      "Epoch 3/90\n",
      "174/174 [==============================] - 51s 292ms/step - loss: 4.6919\n",
      "Epoch 4/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 4.4072\n",
      "Epoch 5/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 4.1703\n",
      "Epoch 6/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 3.9608\n",
      "Epoch 7/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 3.7682\n",
      "Epoch 8/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 3.5926\n",
      "Epoch 9/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 3.4243\n",
      "Epoch 10/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 3.2709\n",
      "Epoch 11/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 3.1290\n",
      "Epoch 12/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 3.0023\n",
      "Epoch 13/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 2.8803\n",
      "Epoch 14/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.7777\n",
      "Epoch 15/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 2.6745\n",
      "Epoch 16/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 2.5811\n",
      "Epoch 17/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.5184\n",
      "Epoch 18/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.4237\n",
      "Epoch 19/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.3568\n",
      "Epoch 20/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.2914\n",
      "Epoch 21/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.2440\n",
      "Epoch 22/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.1752\n",
      "Epoch 23/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 2.1253\n",
      "Epoch 24/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.0889\n",
      "Epoch 25/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 2.0636\n",
      "Epoch 26/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 2.0130\n",
      "Epoch 27/90\n",
      "174/174 [==============================] - 51s 293ms/step - loss: 1.9731\n",
      "Epoch 28/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.9445\n",
      "Epoch 29/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.9135\n",
      "Epoch 30/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.8875\n",
      "Epoch 31/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.8628\n",
      "Epoch 32/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.8444\n",
      "Epoch 33/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.8219\n",
      "Epoch 34/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.7995\n",
      "Epoch 35/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.7819\n",
      "Epoch 36/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.7719\n",
      "Epoch 37/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.7512\n",
      "Epoch 38/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.7431\n",
      "Epoch 39/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.7180\n",
      "Epoch 40/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.7115\n",
      "Epoch 41/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.7056\n",
      "Epoch 42/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.7049\n",
      "Epoch 43/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.6838\n",
      "Epoch 44/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.6667\n",
      "Epoch 45/90\n",
      "174/174 [==============================] - 51s 295ms/step - loss: 1.6554\n",
      "Epoch 46/90\n",
      "174/174 [==============================] - 51s 294ms/step - loss: 1.6496\n",
      "Epoch 47/90\n",
      "174/174 [==============================] - 50s 288ms/step - loss: 1.6618\n",
      "Epoch 48/90\n",
      "174/174 [==============================] - 50s 290ms/step - loss: 1.6945\n",
      "Epoch 49/90\n",
      "174/174 [==============================] - 51s 291ms/step - loss: 1.6593\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение полносвязной RNN модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(RNN_DIR)]\n",
    "simple_rnn_hist = simple_rnn.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K42Iy3mI8eWz",
    "outputId": "b7e6148f-9cd7-4fff-ff45-aa940f7be5b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение однослойной LSTM модели:\n",
      "Epoch 1/90\n",
      "174/174 [==============================] - 55s 314ms/step - loss: 6.2315\n",
      "Epoch 2/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 5.3154\n",
      "Epoch 3/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 4.9633\n",
      "Epoch 4/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 4.7284\n",
      "Epoch 5/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 4.5658\n",
      "Epoch 6/90\n",
      "174/174 [==============================] - 55s 314ms/step - loss: 4.4360\n",
      "Epoch 7/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 4.3177\n",
      "Epoch 8/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 4.2077\n",
      "Epoch 9/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 4.1050\n",
      "Epoch 10/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 4.0073\n",
      "Epoch 11/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 3.9119\n",
      "Epoch 12/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 3.8198\n",
      "Epoch 13/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 3.7284\n",
      "Epoch 14/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 3.6375\n",
      "Epoch 15/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 3.5499\n",
      "Epoch 16/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 3.4612\n",
      "Epoch 17/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 3.3759\n",
      "Epoch 18/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 3.2899\n",
      "Epoch 19/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 3.2041\n",
      "Epoch 20/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 3.1206\n",
      "Epoch 21/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 3.0380\n",
      "Epoch 22/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 2.9553\n",
      "Epoch 23/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.8756\n",
      "Epoch 24/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.7962\n",
      "Epoch 25/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.7181\n",
      "Epoch 26/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.6414\n",
      "Epoch 27/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.5659\n",
      "Epoch 28/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 2.4919\n",
      "Epoch 29/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.4194\n",
      "Epoch 30/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 2.3487\n",
      "Epoch 31/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 2.2793\n",
      "Epoch 32/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 2.2124\n",
      "Epoch 33/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 2.1448\n",
      "Epoch 34/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 2.0809\n",
      "Epoch 35/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 2.0186\n",
      "Epoch 36/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.9564\n",
      "Epoch 37/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.8971\n",
      "Epoch 38/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.8378\n",
      "Epoch 39/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.7806\n",
      "Epoch 40/90\n",
      "174/174 [==============================] - 55s 314ms/step - loss: 1.7238\n",
      "Epoch 41/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.6712\n",
      "Epoch 42/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.6198\n",
      "Epoch 43/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.5694\n",
      "Epoch 44/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.5198\n",
      "Epoch 45/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.4722\n",
      "Epoch 46/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.4246\n",
      "Epoch 47/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.3802\n",
      "Epoch 48/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.3352\n",
      "Epoch 49/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.2926\n",
      "Epoch 50/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.2513\n",
      "Epoch 51/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.2126\n",
      "Epoch 52/90\n",
      "174/174 [==============================] - 55s 314ms/step - loss: 1.1756\n",
      "Epoch 53/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.1363\n",
      "Epoch 54/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.0985\n",
      "Epoch 55/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 1.0621\n",
      "Epoch 56/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 1.0301\n",
      "Epoch 57/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.9965\n",
      "Epoch 58/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.9635\n",
      "Epoch 59/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.9335\n",
      "Epoch 60/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.9030\n",
      "Epoch 61/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.8737\n",
      "Epoch 62/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.8450\n",
      "Epoch 63/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.8180\n",
      "Epoch 64/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.7927\n",
      "Epoch 65/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.7665\n",
      "Epoch 66/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.7417\n",
      "Epoch 67/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.7173\n",
      "Epoch 68/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.6952\n",
      "Epoch 69/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.6709\n",
      "Epoch 70/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.6491\n",
      "Epoch 71/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.6308\n",
      "Epoch 72/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.6099\n",
      "Epoch 73/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.5887\n",
      "Epoch 74/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.5708\n",
      "Epoch 75/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.5534\n",
      "Epoch 76/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.5379\n",
      "Epoch 77/90\n",
      "174/174 [==============================] - 55s 315ms/step - loss: 0.5204\n",
      "Epoch 78/90\n",
      "174/174 [==============================] - 55s 318ms/step - loss: 0.5025\n",
      "Epoch 79/90\n",
      "174/174 [==============================] - 55s 318ms/step - loss: 0.4862\n",
      "Epoch 80/90\n",
      "174/174 [==============================] - 55s 318ms/step - loss: 0.4710\n",
      "Epoch 81/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.4551\n",
      "Epoch 82/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.4405\n",
      "Epoch 83/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.4277\n",
      "Epoch 84/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.4171\n",
      "Epoch 85/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.4067\n",
      "Epoch 86/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.3936\n",
      "Epoch 87/90\n",
      "174/174 [==============================] - 55s 317ms/step - loss: 0.3779\n",
      "Epoch 88/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.3672\n",
      "Epoch 89/90\n",
      "174/174 [==============================] - 55s 316ms/step - loss: 0.3566\n",
      "Epoch 90/90\n",
      "174/174 [==============================] - 55s 318ms/step - loss: 0.3487\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение однослойной LSTM модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(SINGLE_DIR)]\n",
    "single_lstm_hist = single_lstm.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UdudED1J8eXL",
    "outputId": "559489cc-bc15-4d51-cd3b-1c2dcf7a546f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение двухслойной LSTM модели:\n",
      "Epoch 1/90\n",
      "174/174 [==============================] - 67s 388ms/step - loss: 6.5878\n",
      "Epoch 2/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 6.1277\n",
      "Epoch 3/90\n",
      "174/174 [==============================] - 67s 387ms/step - loss: 5.7320\n",
      "Epoch 4/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 5.4157\n",
      "Epoch 5/90\n",
      "174/174 [==============================] - 67s 387ms/step - loss: 5.2170\n",
      "Epoch 6/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 5.0735\n",
      "Epoch 7/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 4.9510\n",
      "Epoch 8/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 4.8398\n",
      "Epoch 9/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 4.7197\n",
      "Epoch 10/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 4.5994\n",
      "Epoch 11/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 4.5021\n",
      "Epoch 12/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 4.4077\n",
      "Epoch 13/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 4.3095\n",
      "Epoch 14/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 4.2075\n",
      "Epoch 15/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 4.0995\n",
      "Epoch 16/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 3.9873\n",
      "Epoch 17/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 3.8699\n",
      "Epoch 18/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 3.7527\n",
      "Epoch 19/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 3.6366\n",
      "Epoch 20/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 3.5257\n",
      "Epoch 21/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 3.4152\n",
      "Epoch 22/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 3.3061\n",
      "Epoch 23/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 3.1981\n",
      "Epoch 24/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 3.0953\n",
      "Epoch 25/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 2.9908\n",
      "Epoch 26/90\n",
      "174/174 [==============================] - 68s 388ms/step - loss: 2.8913\n",
      "Epoch 27/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 2.7937\n",
      "Epoch 28/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 2.6985\n",
      "Epoch 29/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 2.6087\n",
      "Epoch 30/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 2.5158\n",
      "Epoch 31/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 2.4271\n",
      "Epoch 32/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 2.3385\n",
      "Epoch 33/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 2.2520\n",
      "Epoch 34/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 2.1728\n",
      "Epoch 35/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 2.0933\n",
      "Epoch 36/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 2.0254\n",
      "Epoch 37/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 1.9407\n",
      "Epoch 38/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 1.8666\n",
      "Epoch 39/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.7899\n",
      "Epoch 40/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.7205\n",
      "Epoch 41/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 1.6531\n",
      "Epoch 42/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 1.5888\n",
      "Epoch 43/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.5228\n",
      "Epoch 44/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.4600\n",
      "Epoch 45/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 1.3987\n",
      "Epoch 46/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 1.3374\n",
      "Epoch 47/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 1.2757\n",
      "Epoch 48/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 1.2187\n",
      "Epoch 49/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.1652\n",
      "Epoch 50/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.1191\n",
      "Epoch 51/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 1.0608\n",
      "Epoch 52/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 1.0078\n",
      "Epoch 53/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.9603\n",
      "Epoch 54/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.9158\n",
      "Epoch 55/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.8675\n",
      "Epoch 56/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.8292\n",
      "Epoch 57/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.7875\n",
      "Epoch 58/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.7487\n",
      "Epoch 59/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.7122\n",
      "Epoch 60/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.6750\n",
      "Epoch 61/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.6395\n",
      "Epoch 62/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.6036\n",
      "Epoch 63/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.5675\n",
      "Epoch 64/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.5325\n",
      "Epoch 65/90\n",
      "174/174 [==============================] - 67s 384ms/step - loss: 0.5039\n",
      "Epoch 66/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.4792\n",
      "Epoch 67/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.4622\n",
      "Epoch 68/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.4376\n",
      "Epoch 69/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.4120\n",
      "Epoch 70/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.3828\n",
      "Epoch 71/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.3625\n",
      "Epoch 72/90\n",
      "174/174 [==============================] - 67s 387ms/step - loss: 0.3437\n",
      "Epoch 73/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.3288\n",
      "Epoch 74/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.3175\n",
      "Epoch 75/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.3029\n",
      "Epoch 76/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.2835\n",
      "Epoch 77/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.2585\n",
      "Epoch 78/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.2430\n",
      "Epoch 79/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.2241\n",
      "Epoch 80/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.2076\n",
      "Epoch 81/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.1935\n",
      "Epoch 82/90\n",
      "174/174 [==============================] - 67s 386ms/step - loss: 0.1856\n",
      "Epoch 83/90\n",
      "174/174 [==============================] - 67s 385ms/step - loss: 0.1848\n",
      "Epoch 84/90\n",
      "174/174 [==============================] - 65s 375ms/step - loss: 0.1964\n",
      "Epoch 85/90\n",
      "174/174 [==============================] - 65s 376ms/step - loss: 0.3324\n",
      "Epoch 86/90\n",
      "174/174 [==============================] - 65s 376ms/step - loss: 0.4986\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение двухслойной LSTM модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(DOUBLE_DIR)]\n",
    "double_lstm_hist = double_lstm.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PIWwVD_38eXc",
    "outputId": "45b9ca2a-3166-4b1c-e3d8-c93343f5458f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение однослойной GRU модели:\n",
      "Epoch 1/90\n",
      "174/174 [==============================] - 53s 304ms/step - loss: 5.9885\n",
      "Epoch 2/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 5.1874\n",
      "Epoch 3/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 4.8453\n",
      "Epoch 4/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 4.5959\n",
      "Epoch 5/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 4.3791\n",
      "Epoch 6/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 4.1814\n",
      "Epoch 7/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 3.9939\n",
      "Epoch 8/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 3.8149\n",
      "Epoch 9/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 3.6433\n",
      "Epoch 10/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 3.4771\n",
      "Epoch 11/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 3.3137\n",
      "Epoch 12/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 3.1509\n",
      "Epoch 13/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 2.9912\n",
      "Epoch 14/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 2.8360\n",
      "Epoch 15/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 2.6874\n",
      "Epoch 16/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 2.5459\n",
      "Epoch 17/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 2.4123\n",
      "Epoch 18/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 2.2869\n",
      "Epoch 19/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 2.1692\n",
      "Epoch 20/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 2.0601\n",
      "Epoch 21/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.9584\n",
      "Epoch 22/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 1.8637\n",
      "Epoch 23/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.7759\n",
      "Epoch 24/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.6957\n",
      "Epoch 25/90\n",
      "174/174 [==============================] - 53s 304ms/step - loss: 1.6208\n",
      "Epoch 26/90\n",
      "174/174 [==============================] - 53s 304ms/step - loss: 1.5506\n",
      "Epoch 27/90\n",
      "174/174 [==============================] - 53s 304ms/step - loss: 1.4871\n",
      "Epoch 28/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 1.4260\n",
      "Epoch 29/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 1.3710\n",
      "Epoch 30/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 1.3186\n",
      "Epoch 31/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 1.2693\n",
      "Epoch 32/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 1.2228\n",
      "Epoch 33/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.1807\n",
      "Epoch 34/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.1404\n",
      "Epoch 35/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.1042\n",
      "Epoch 36/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 1.0700\n",
      "Epoch 37/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 1.0371\n",
      "Epoch 38/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 1.0050\n",
      "Epoch 39/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.9756\n",
      "Epoch 40/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.9473\n",
      "Epoch 41/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.9204\n",
      "Epoch 42/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.8966\n",
      "Epoch 43/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.8752\n",
      "Epoch 44/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.8528\n",
      "Epoch 45/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.8295\n",
      "Epoch 46/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.8110\n",
      "Epoch 47/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.7906\n",
      "Epoch 48/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.7725\n",
      "Epoch 49/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.7560\n",
      "Epoch 50/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.7408\n",
      "Epoch 51/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.7258\n",
      "Epoch 52/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.7145\n",
      "Epoch 53/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.6974\n",
      "Epoch 54/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.6805\n",
      "Epoch 55/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.6697\n",
      "Epoch 56/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.6583\n",
      "Epoch 57/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.6469\n",
      "Epoch 58/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.6336\n",
      "Epoch 59/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.6200\n",
      "Epoch 60/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.6088\n",
      "Epoch 61/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5982\n",
      "Epoch 62/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.5915\n",
      "Epoch 63/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.5834\n",
      "Epoch 64/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.5774\n",
      "Epoch 65/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.5708\n",
      "Epoch 66/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.5626\n",
      "Epoch 67/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5506\n",
      "Epoch 68/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5429\n",
      "Epoch 69/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5337\n",
      "Epoch 70/90\n",
      "174/174 [==============================] - 53s 305ms/step - loss: 0.5238\n",
      "Epoch 71/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.5183\n",
      "Epoch 72/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5118\n",
      "Epoch 73/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5067\n",
      "Epoch 74/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.5046\n",
      "Epoch 75/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.5022\n",
      "Epoch 76/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.4985\n",
      "Epoch 77/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.4984\n",
      "Epoch 78/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.4939\n",
      "Epoch 79/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.4878\n",
      "Epoch 80/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.4791\n",
      "Epoch 81/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.4649\n",
      "Epoch 82/90\n",
      "174/174 [==============================] - 53s 307ms/step - loss: 0.4531\n",
      "Epoch 83/90\n",
      "174/174 [==============================] - 53s 306ms/step - loss: 0.4446\n",
      "Epoch 84/90\n",
      "174/174 [==============================] - 54s 308ms/step - loss: 0.4409\n",
      "Epoch 85/90\n",
      "174/174 [==============================] - 52s 300ms/step - loss: 0.4409\n",
      "Epoch 86/90\n",
      "174/174 [==============================] - 52s 300ms/step - loss: 0.4427\n",
      "Epoch 87/90\n",
      "174/174 [==============================] - 52s 300ms/step - loss: 0.4474\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучение однослойной GRU модели:\")\n",
    "\n",
    "my_callbacks = [EarlyStopping(monitor=\"loss\", patience=3), checkpoint_creator(GRU_DIR)]\n",
    "single_gru_hist = single_gru.fit(dataset, epochs=EPOCHS, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgGI0AaZ8eXt"
   },
   "source": [
    "Процес обучения можно представить на графике зависимости функционала потерь от количества эпох:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "kDD4CXEb8eXv",
    "outputId": "3a018ed9-7105-4137-b6e6-06f519d71499"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 460.8x403.2 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(simple_rnn_hist.history['loss'])\n",
    "plt.plot(single_lstm_hist.history['loss'])\n",
    "plt.plot(double_lstm_hist.history['loss'])\n",
    "plt.plot(single_gru_hist.history['loss'], color = 'green')\n",
    "plt.title('Потери различных архетектур сетей')\n",
    "plt.ylabel('Потери')\n",
    "plt.xlabel('Количество эпох')\n",
    "plt.legend(['Полносвязная RNN', 'Однослойная LSTM', 'Двухслойная LSTM', \n",
    "            'Однослойная GRU'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U_o-rGtq8eX8"
   },
   "source": [
    "### Демонстрация работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HN3LSvo8eX9"
   },
   "source": [
    "#### Подготовка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iua6dapA8eYD"
   },
   "source": [
    "Полученные нами модели построены для обучения на пакетах размера **BATCH_SIZE**, однако при генерации текста мы отправляем в модель одну последовательность произвольного размера. Поэтому перестроим наши модели для еденичного размера пакета и загрузим в них веса обученных моделей из контрольных точек. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06ORfxbZ8eYE"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(RNN_DIR, \"checkpoints/\")\n",
    "\n",
    "simple_rnn = ModelRNN(w2v, 1, UNITS, NEUROS, RATE)\n",
    "simple_rnn.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "simple_rnn.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrUl93QC8eYT"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(SINGLE_DIR, \"checkpoints/\")\n",
    "\n",
    "single_lstm = ModelSingleLSTM(w2v, 1, UNITS, NEUROS, RATE)\n",
    "single_lstm.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "single_lstm.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVmt7YoY8eYZ"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(DOUBLE_DIR, \"checkpoints/\")\n",
    "\n",
    "double_lstm = ModelDoubleLSTM(w2v, 1, UNITS, NEUROS, RATE)\n",
    "double_lstm.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "double_lstm.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zUSaET18eYq"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = os.path.join(GRU_DIR, \"checkpoints/\")\n",
    "\n",
    "single_gru = ModelGRU(w2v, 1, UNITS, NEUROS, RATE)\n",
    "single_gru.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "single_gru.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4jRAVoOq8eY5"
   },
   "source": [
    "Предсказанная рекуррентной моделью последовательность слов пред объединением в текст требует обработки. Простейшая функция обработки для обработки представлена здесь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMCPFdUE8eY_"
   },
   "source": [
    "#### Сохранение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mTy39hf8eZA"
   },
   "source": [
    "Для того, что бы не обучать модели заново в будущем, сохраним их дл будущего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eR1c8zd38eZB"
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(RNN_DIR, \"simple_rnn.h5\")\n",
    "simple_rnn.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YAZfKY28eZI"
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(SINGLE_DIR, \"single_lstm.h5\")\n",
    "single_lstm.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_42NIf8B8eZP"
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(DOUBLE_DIR, \"double_lstm.h5\")\n",
    "double_lstm.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YewoDUpr8eZV"
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(GRU_DIR, \"single_gru.h5\")\n",
    "single_gru.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dTrnhQ9z8eZ1"
   },
   "source": [
    "#### Генерация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейший преобразователь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b3DFBaFI8eZ2"
   },
   "outputs": [],
   "source": [
    "def list_to_text(words):\n",
    "  ans = \"\"\n",
    "  higher = False\n",
    "  puncts = {\".\", \",\", \":\", \"!\", \"?\", \";\", '\"', \"'\", \"’\"}\n",
    "  enders = {\".\", \"?\", \"!\"}\n",
    "  for word in words:\n",
    "    if higher:\n",
    "      word = word.capitalize()\n",
    "    if word in puncts:\n",
    "      ans += word\n",
    "    else:\n",
    "      ans += \" \" + word\n",
    "    \n",
    "    higher = False\n",
    "    if word in enders:\n",
    "      higher = True\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9eqGG2K8eaB"
   },
   "source": [
    "Основная функция генерации текста. Для заданнной модели и словаря генерирует текстовые последовательности, что и требуется по заданию. \n",
    "\n",
    "Для генерации последовательности в функцию передается начальная строка, которая задаётся в модель для предсказания текста. Этот текст пробразуется функцией выше в читаемый вид."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwj2jCLg8eaP"
   },
   "outputs": [],
   "source": [
    "def generate_text(model, word2idx, idx2word, start_string, num_generate=20):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  seq = tokenize_text(start_string)\n",
    "\n",
    "  converter = lambda x: word_to_int(x, word2idx)\n",
    "  input_eval = list(map(converter, seq))\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.25\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "  return start_string + list_to_text(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "3_4-c6bD8eag",
    "outputId": "25fef7ec-5533-4fab-8105-dc7b49b51871"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be best of the circumstantial scandal, with the new friend Mr. Grimwig. Like this, some kind looking twice routed themselves above its originator, her better effect upon the face opposite intentions in his respect habitual feeling absolutely chance to extreme seriousness, he thought: one no'"
      ]
     },
     "execution_count": 129,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(simple_rnn, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "UO5sD07w8ean",
    "outputId": "26a557fb-61bc-4e6f-ac12-bbbf5f1eb0e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be out his heart, they parted behind the FIRST him too, so the expression ( alas! I repeat Dorian Gray with closed out where can’ t know where i know how came in September Dounia’ s stifling daily in what was nothing about him. ” she'"
      ]
     },
     "execution_count": 132,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(single_lstm, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "DdERnTSp8ebN",
    "outputId": "13fe624d-cec4-4598-97bc-ade078303113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I predict that it will be necessary that they lie, so fond of harm, that you would do sit down his usual, i must close to her supper for Avdotya Romanovna began all, as he had rented worse. Mortimer, according to find himself. The best. 'that for the\""
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(double_lstm, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "BCze2UgM-Qwg",
    "outputId": "c4df88c4-f7e5-4389-9503-3596af756a74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I predict that it will be too. She was fine day his eyes on, Vronsky felt at self-knowledge, who can promise? If anyone of his wont to ask of politics and motion, that Sviazhsky, i have something fine as well; it soon she added, the care of roses'"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(single_gru, word2idx, idx2word, \"I predict that it will be\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEh9UL3b8ebi"
   },
   "source": [
    "### Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jqtZMO9E8ebk"
   },
   "source": [
    "В результате мы получили 4 нейронных сети с рекуррентными слоями различных архитектур и посмотрели на то, как каждая из них генерирует последовательности слов и можем оценить насколько сгенерированные последовательности похожи на те, которые производит человек. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohh0VEb28ebt"
   },
   "source": [
    "Перед тем, как залить репозиторий на *GitHub*, я удалю все чекпоины и файлы моделей, котрые создавал в процессе, поскольку их вес слишком велик. Если вам действительно нужны полученные модели, удалите последнюю строчку кода, которая будет приямо под этой записью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cF8OrwID8ebw"
   },
   "outputs": [],
   "source": [
    "rm -rf single_lstm full_rnn double_lstm single_gru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dBkGCq4S8ecI"
   },
   "source": [
    "<h5> <center>Сделано Бронниковым Максимом</center> </h5>\n",
    "<h5> <center>25.05.2020</center> </h5>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GenerationP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
